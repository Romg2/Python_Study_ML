{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**기본 세팅**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "mpl.rc('font', family='NanumGothic') # 폰트 설정\n",
    "mpl.rc('axes', unicode_minus=False) # 유니코드에서 음수 부호 설정\n",
    "\n",
    "# 차트 스타일 설정\n",
    "sns.set(font=\"NanumGothic\", rc={\"axes.unicode_minus\":False}, style='darkgrid')\n",
    "plt.rc(\"figure\", figsize=(10,8))\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 한글 텍스트 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 네이버 영화 평점 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터는 <https://github.com/e9t/nsmc>에서 받을 수 있다.\n",
    "\n",
    "이 데이터를 이용해서 감성 분석을 진행해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                           document  label\n",
       "0   9976970                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                  너무재밓었다그래서보는것을추천한다      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('nsmc-master/ratings_train.txt', sep='\\t')\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    75173\n",
       "1    74827\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0은 부정 감성, 1은 긍정 감성을 의미한다.\n",
    "\n",
    "\n",
    "- target의 분포는 거의 균등하게 나타났다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   id        150000 non-null  int64 \n",
      " 1   document  149995 non-null  object\n",
      " 2   label     150000 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터는 150,000 x 3으로 이루어져 있다.\n",
    "\n",
    "\n",
    "- document 컬럼은 일부 결측이 존재하여 이를 공백으로 변환하겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.1 텍스트 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# document 결측 공백으로 변환\n",
    "train_df = train_df.fillna(\" \")\n",
    "\n",
    "# 정규 표현식으로 숫자를 공백으로 변경 (정규 표현식에서 \\d는 숫자를 의미)\n",
    "train_df[\"document\"] = train_df[\"document\"].apply(lambda x: re.sub(r\"\\d+\", \" \", x))\n",
    "\n",
    "# test set 동일 작업\n",
    "test_df = pd.read_csv('nsmc-master/ratings_test.txt', sep='\\t')\n",
    "test_df = test_df.fillna(\" \")\n",
    "test_df[\"document\"] = test_df[\"document\"].apply(lambda x: re.sub(r\"\\d+\", \" \", x))\n",
    "\n",
    "# id 컬럼 제거\n",
    "train_df.drop(\"id\", axis=1, inplace=True)\n",
    "test_df.drop(\"id\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- document 결측값과 숫자를 공백으로 변환하였고 id 컬럼은 제거하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.2 감성 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tokenizer 함수**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter\n",
    "\n",
    "twitter = Twitter()\n",
    "\n",
    "def tw_tokenizer(text):\n",
    "    # 텍스트를 형태소 단어로 토큰화 후 리스트로 반환\n",
    "    tokens_ko = twitter.morphs(text)\n",
    "    \n",
    "    return tokens_ko"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 피처 벡터화에 사용할 tokenizer 함수를 생성하였다.\n",
    "\n",
    "\n",
    "- `twitter.morphs()`는 문장을 형태소 단어 형태로 토큰화 한다.\n",
    "\n",
    "\n",
    "- `Twitter`는 현재 `Okt`(Open Korea Text)로 변경되었고, 여기선 그냥 `Twitter`로 썼다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 85.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr_clf__C': 3.5} 0.8616\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# TF-IDF 피처 벡터화, 로지스틱\n",
    "pipeline = Pipeline([\n",
    "    (\"tfidf_vect\", TfidfVectorizer(tokenizer=tw_tokenizer, ngram_range=(1,2), min_df=3, max_df=0.9)), \n",
    "    (\"lr_clf\", LogisticRegression())\n",
    "])\n",
    "\n",
    "# GridSearchCV\n",
    "params = {\n",
    "    \"lr_clf__C\": [1, 3.5, 10]\n",
    "}\n",
    "\n",
    "grid_cv = GridSearchCV(pipeline, param_grid=params, scoring=\"accuracy\", verbose=1)\n",
    "grid_cv.fit(train_df['document'], train_df['label'])\n",
    "\n",
    "print(grid_cv.best_params_, round(grid_cv.best_score_,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 파이프라인을 이용해 TF-IDF 피처 벡터화, 로지스틱 회귀 객체를 생성하였다.\n",
    "\n",
    "\n",
    "- 수행 시간을 고려해서 하이퍼 파라미터는 3개 중 최적을 찾았다.\n",
    "\n",
    "\n",
    "- 최적 하이퍼 파라미터 C는 3.5일 때 최고 0.8616의 정확도로 나타났다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression 정확도: 0.8618\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 예측/평가 (best_estimator로 안해도 이미 최적으로 학습되어 있음)\n",
    "best_estimator = grid_cv.best_estimator_\n",
    "pred = best_estimator.predict(test_df[\"document\"])\n",
    "acc = accuracy_score(test_df[\"label\"], pred)\n",
    "\n",
    "print(f\"Logistic Regression 정확도: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test에 대한 정확도는 0.8618로 나타났다.\n",
    "\n",
    "\n",
    "- 피처 벡터화시 반드시 train으로 학습한 벡터화 객체로 test를 벡터화 하여야한다.\n",
    "\n",
    "\n",
    "- 여기선 파이프라인을 사용했기에 예측시 원래 객체로 입력하였다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "310.417px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
