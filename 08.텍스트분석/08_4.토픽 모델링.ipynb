{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**기본 세팅**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "mpl.rc('font', family='NanumGothic') # 폰트 설정\n",
    "mpl.rc('axes', unicode_minus=False) # 유니코드에서 음수 부호 설정\n",
    "\n",
    "# 차트 스타일 설정\n",
    "sns.set(font=\"NanumGothic\", rc={\"axes.unicode_minus\":False}, style='darkgrid')\n",
    "plt.rc(\"figure\", figsize=(10,8))\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 토픽 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텍스트 요약 기법인 토픽 모델링은 문서 집합에 숨어 있는 주제를 찾아내는 방법이다.\n",
    "\n",
    "머신러닝 기반의 토픽 모델링은 주로 LSA(Latent Semantic Analysis)와 LDA(Latent Dirichlet Allocation)을 사용한다.\n",
    "\n",
    "여기선 LDA 기반 토픽 모델링을 적용해본다(선형 판별 분석 LDA와 다름 유의)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# 모토사이클, 야구, 그래픽스, 윈도우즈, 중동, 기독교, 전자공학, 의학 8개 주제 추출\n",
    "cats = ['rec.motorcycles', 'rec.sport.baseball', 'comp.graphics', 'comp.windows.x',\n",
    "        'talk.politics.mideast', 'soc.religion.christian', 'sci.electronics', 'sci.med'  ]\n",
    "\n",
    "# 위에서 지정한 주제만 추출\n",
    "news_df= fetch_20newsgroups(subset='all',remove=('headers', 'footers', 'quotes'), \n",
    "                            categories=cats, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사이킷런 내부 데이터 20 뉴스그룹 데이터 셋에서 일부 주제의 기사만 추출하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer Shape: (7862, 1000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# LDA는 CountVectorizer만 적용\n",
    "count_vect = CountVectorizer(max_df=0.95, max_features=1000, min_df=2, stop_words='english', ngram_range=(1,2))\n",
    "feat_vect = count_vect.fit_transform(news_df.data)\n",
    "\n",
    "print('CountVectorizer Shape:', feat_vect.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `max_df`로 빈도수가 95% 이내인 단어만 추출한다.\n",
    "\n",
    "\n",
    "- `max_features`로 피처의 갯수는 가장 높은 빈도를 가진 단어 순으로 1,000개 사용\n",
    "\n",
    "\n",
    "- `min_df`로 빈도수가 2 이하인 단어는 제외\n",
    "\n",
    "\n",
    "- LDA에서 피처 벡터화는 CountVectorizer만 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=8, random_state=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=8, random_state=0)\n",
    "lda.fit(feat_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LDA에서 `n_components`로 토픽의 갯수를 조정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.60992018e+01, 1.35626798e+02, 2.15751867e+01, ...,\n",
       "        3.02911688e+01, 8.66830093e+01, 6.79285199e+01],\n",
       "       [1.25199920e-01, 1.44401815e+01, 1.25045596e-01, ...,\n",
       "        1.81506995e+02, 1.25097844e-01, 9.39593286e+01],\n",
       "       [3.34762663e+02, 1.25176265e-01, 1.46743299e+02, ...,\n",
       "        1.25105772e-01, 3.63689741e+01, 1.25025218e-01],\n",
       "       ...,\n",
       "       [3.60204965e+01, 2.08640688e+01, 4.29606813e+00, ...,\n",
       "        1.45056650e+01, 8.33854413e+00, 1.55690009e+01],\n",
       "       [1.25128711e-01, 1.25247756e-01, 1.25005143e-01, ...,\n",
       "        9.17278769e+01, 1.25177668e-01, 3.74575887e+01],\n",
       "       [5.49258690e+01, 4.47009532e+00, 9.88524814e+00, ...,\n",
       "        4.87048440e+01, 1.25034678e-01, 1.25074632e-01]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `components_` 속성은 각 토픽별로 word 피처가 해당 토픽에 얼마나 할당됐는지 수치로 나타낸다.\n",
    "\n",
    "\n",
    "- 값이 클수록 해당 word 피처는 그 토픽의 중심 word가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(lda.components_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 앞서 토픽의 갯수는 8, 피처의 수는 1,000개로 제한하여 8 x 1,000으로 나타났다.\n",
    "\n",
    "\n",
    "- 어떠한 피처가 연관성이 높은지 함수로 만들어 보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word 피처명 추출 함수**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    topic_news20 = [\"모토사이클\", \"야구\", \"그래픽스\", \"윈도우즈\", \"중동\", \"기독교\", \"전자공학\", \"의학\"]\n",
    "    \n",
    "    for topic_index, topic in enumerate(model.components_):\n",
    "        print('Topic #', topic_index + 1, topic_news20[topic_index])\n",
    "\n",
    "        # 각 토픽별 word 피처 연관도 내림차순 정렬시 값들의 index 반환 .. (1)\n",
    "        topic_word_indexes = topic.argsort()[::-1] # [::-1] 역순으로 정렬\n",
    "        top_indexes = topic_word_indexes[:no_top_words]\n",
    "        \n",
    "        # (1)의 index로 피처 이름명 추출\n",
    "        feature_concat = '/'.join([feature_names[i] for i in top_indexes])                \n",
    "        \n",
    "        print(feature_concat)\n",
    "        print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic # 1 모토사이클\n",
      "year/10/game/medical/health/team/12/20/disease/cancer/1993/games/years/patients/good\n",
      " \n",
      "Topic # 2 야구\n",
      "don/just/like/know/people/said/think/time/ve/didn/right/going/say/ll/way\n",
      " \n",
      "Topic # 3 그래픽스\n",
      "image/file/jpeg/program/gif/images/output/format/files/color/entry/00/use/bit/03\n",
      " \n",
      "Topic # 4 윈도우즈\n",
      "like/know/don/think/use/does/just/good/time/book/read/information/people/used/post\n",
      " \n",
      "Topic # 5 중동\n",
      "armenian/israel/armenians/jews/turkish/people/israeli/jewish/government/war/dos dos/turkey/arab/armenia/000\n",
      " \n",
      "Topic # 6 기독교\n",
      "edu/com/available/graphics/ftp/data/pub/motif/mail/widget/software/mit/information/version/sun\n",
      " \n",
      "Topic # 7 전자공학\n",
      "god/people/jesus/church/believe/christ/does/christian/say/think/christians/bible/faith/sin/life\n",
      " \n",
      "Topic # 8 의학\n",
      "use/dos/thanks/windows/using/window/does/display/help/like/problem/server/need/know/run\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# CountVectorizer 객체의 전체 word 명칭\n",
    "feature_names = count_vect.get_feature_names()\n",
    "\n",
    "# Topic별 가장 연관도가 높은 word 15개\n",
    "display_topics(lda, feature_names, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 벡터 객체의 `get_feature_names()`을 이용해 전체 word 피처 명칭을 알 수 있다.\n",
    "\n",
    "\n",
    "- 각 토픽별로 연관성이 높은 단어를 봤을 때 그래픽스는 image, jpeg등 관련 주제어가 잘 추출되었다.\n",
    "\n",
    "\n",
    "- 나머지에선 어느 정도 맞기도 하고 아니기도 하고 애매하다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
