{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**기본 세팅**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "mpl.rc('font', family='NanumGothic') # 폰트 설정\n",
    "mpl.rc('axes', unicode_minus=False) # 유니코드에서 음수 부호 설정\n",
    "\n",
    "# 차트 스타일 설정\n",
    "sns.set(font=\"NanumGothic\", rc={\"axes.unicode_minus\":False}, style='darkgrid')\n",
    "plt.rc(\"figure\", figsize=(10,8))\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 감성 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텍스트에서 나타나는 감정/판단/믿음/의견/기분 등의 주관적인 요소를 분석하는 기법\n",
    "\n",
    "SNS에서 감정 분석, 영화나 제품에 대한 긍정 또는 리뷰, 여론조사 의견 분석 등에 사용한다.\n",
    "\n",
    "여러 가지 주관적인 단어와 문맥을 기반으로 감성 수치를 계산한다.\n",
    "\n",
    "지도학습, 비지도학습 모두 가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 지도학습: 일반적으로 적용해온 학습/예측 과정으로 텍스트 기반의 분류와 거의 동일하다.\n",
    "\n",
    "\n",
    "- 비지도학습: Lexicon이라는 감성 어휘 사전을 이용하여 문서의 긍정, 부정 감성 여부를 판단한다.\n",
    "\n",
    "\n",
    "Lexicon은 감성 분석을 위한 용어와 문맥에 대한 다양한 정보를 가지고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 지도학습 감성 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실습 데이터로 [캐글 IMDB 영화평 데이터](https://www.kaggle.com/c/word2vec-nlp-tutorial/data)를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**데이터 구조**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- id: 각 데이터의 id\n",
    "\n",
    "\n",
    "- sentiment: 영화평(review)의 결과값, 1은 긍정, 0은 부정\n",
    "\n",
    "\n",
    "- review: 영화평 텍스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>\"3453_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It seems like more consideration has gone int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>\"5064_1\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"I don't believe they made this film. Complete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>\"10905_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Guy is a loser. Can't get girls, needs to bui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>\"10194_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"This 30 minute documentary Buñuel made in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>\"8478_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"I saw this movie as a child and it broke my h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  sentiment                                             review\n",
       "24995   \"3453_3\"          0  \"It seems like more consideration has gone int...\n",
       "24996   \"5064_1\"          0  \"I don't believe they made this film. Complete...\n",
       "24997  \"10905_3\"          0  \"Guy is a loser. Can't get girls, needs to bui...\n",
       "24998  \"10194_3\"          0  \"This 30 minute documentary Buñuel made in the...\n",
       "24999   \"8478_8\"          1  \"I saw this movie as a child and it broke my h..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df = pd.read_csv(\"./labeledTrainData.tsv\", sep=\"\\t\", quoting=3)\n",
    "review_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `quoting = 3`은 큰 따옴표를 무시하도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"With all this stuff going down at the moment with MJ i've started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ's feeling towards the press and also the obvious message of drugs are bad m'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.<br /><br />The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci's character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ's music.<br /><br />Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.<br /><br />Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ's bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i've gave this subject....hmmm well i don't know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter.\"\n"
     ]
    }
   ],
   "source": [
    "print(review_df[\"review\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 영화평 텍스트를 확인하니 HTML 형식에서 추출하여 \\<br /> 태그가 존재한다.\n",
    "\n",
    "\n",
    "- 해당 문자열은 피처로 만들 필요가 없어 삭제한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 텍스트 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# <br> HTML 태그 공백으로 변환\n",
    "review_df[\"review\"] = review_df[\"review\"].str.replace(\"<br />\", \" \")\n",
    "\n",
    "# 영어가 아닌 문자 제거\n",
    "# re.sub(정규표현식, new_text, old_text)\n",
    "review_df[\"review\"] = review_df[\"review\"].apply( lambda x : re.sub(\"[^a-zA-Z]\", \" \", x) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 판다스 시리즈 객체에 str을 적용하면 다양한 문자열 연산이 가능하다.\n",
    "\n",
    "\n",
    "- 여기선 앞서 확인한 HTML 태그를 공백으로 바꿨다.\n",
    "\n",
    "\n",
    "- 정규식을 이용해서 영어 대/소문자가 아닌 모든 문자를 공백으로 바꿨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17500,), (7500,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y_target = review_df[\"sentiment\"]\n",
    "X_feature = review_df[\"review\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X_feature, y_target, test_size=0.3, random_state=156)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train, test를 각각 17,500개, 7,500개로 나누었다.\n",
    "\n",
    "\n",
    "- 피처로는 id는 제외하고 review만 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 피처 벡터화 및 ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 0.8860, ROC-AUC: 0.9503\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# 피처 벡터화: CountVectorizer, ML: LogisticRegression\n",
    "pipeline = Pipeline([\n",
    "    (\"cnt_vect\", CountVectorizer(stop_words=\"english\", ngram_range=(1,2) ) ),\n",
    "    (\"LR\", LogisticRegression(C=10) )\n",
    "])\n",
    "\n",
    "# 학습/예측/평가\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "pred = pipeline.predict(X_test)\n",
    "pred_prob = pipeline.predict_proba(X_test)[:,1]\n",
    "\n",
    "acc_lr = accuracy_score(y_test, pred)\n",
    "auc_lr = roc_auc_score(y_test, pred_prob)\n",
    "\n",
    "print(f\"예측 정확도: {acc_lr:.4f}, ROC-AUC: {auc_lr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 피처 벡터화는 `CountVectorizer()`, ML은 `LogisticRegression()`을 사용하였다.\n",
    "\n",
    "\n",
    "- 각 파라미터는 임의로 설정하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 0.8936, ROC-AUC: 0.9598\n"
     ]
    }
   ],
   "source": [
    "# 피처 벡터화: TfidfVectorizer, ML: LogisticRegression\n",
    "pipeline = Pipeline([\n",
    "    (\"tfidf_vect\", TfidfVectorizer(stop_words=\"english\", ngram_range=(1,2) ) ),\n",
    "    (\"LR\", LogisticRegression(C=10) )\n",
    "])\n",
    "\n",
    "# 학습/예측/평가\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "pred = pipeline.predict(X_test)\n",
    "pred_prob = pipeline.predict_proba(X_test)[:,1]\n",
    "\n",
    "acc_lr = accuracy_score(y_test, pred)\n",
    "auc_lr = roc_auc_score(y_test, pred_prob)\n",
    "\n",
    "print(f\"예측 정확도: {acc_lr:.4f}, ROC-AUC: {auc_lr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 피처 벡터화를 `TfidfVectorizer()`를 사용하였다.\n",
    "\n",
    "\n",
    "- Count 벡터화에 비해 예측 성능이 향상되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 비지도학습 감성 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비지도학습 감성 분석은 Lexicon이라는 감성 사전을 기반으로 이루어진다.\n",
    "\n",
    "감성 사전은 긍정 또는 부정 감성의 정도를 의미하는 수치, 감성 지수를 가지고 있다.\n",
    "\n",
    "감성 지수는 단어의 위치, 주변 단어, 문맥, 품사(POS) 등을 참고해 결정된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 WordNet 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# NLTK 모든 데이터 셋과 패키지 다운\n",
    "# nltk.download(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WordNet**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WordNet을 이용해 Synsets(Sets of cognitive synonyms)를 이해해보자.\n",
    "\n",
    "Synsets은 단어가 가지는 문맥, 시맨틱 정보를 제공하는 WordNet에서의 핵심 개념이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synsets() 반환 type : <class 'list'>\n",
      "synsets() 반환 값 갯수: 18\n",
      "synsets() 반환 값 : [Synset('present.n.01'), Synset('present.n.02'), Synset('present.n.03'), Synset('show.v.01'), Synset('present.v.02'), Synset('stage.v.01'), Synset('present.v.04'), Synset('present.v.05'), Synset('award.v.01'), Synset('give.v.08'), Synset('deliver.v.01'), Synset('introduce.v.01'), Synset('portray.v.04'), Synset('confront.v.03'), Synset('present.v.12'), Synset('salute.v.06'), Synset('present.a.01'), Synset('present.a.02')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "term = 'present'\n",
    "\n",
    "# present로 wordnet의 synsets 생성\n",
    "synsets = wn.synsets(term)\n",
    "\n",
    "print('synsets() 반환 type :', type(synsets))\n",
    "print('synsets() 반환 값 갯수:', len(synsets))\n",
    "print('synsets() 반환 값 :', synsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- present에 wordnet의 `synsets()`을 적용하였다.\n",
    "\n",
    "\n",
    "- Synset은 하나의 단어가 가지는 여러 시맨틱 정보를 개별 클래스로 나타낸다.\n",
    "\n",
    "\n",
    "- 반환 값에서 present.n.01은 present는 의미, n은 명사 품사, 01은 명사 의미를 구분하는 인덱스이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Synset name :  present.n.01 #####\n",
      "POS : noun.time\n",
      "Definition: the period of time that is happening now; any continuous stretch of time including the moment of speech\n",
      "Lemmas: ['present', 'nowadays']\n",
      "\n",
      "\n",
      "##### Synset name :  present.n.02 #####\n",
      "POS : noun.possession\n",
      "Definition: something presented as a gift\n",
      "Lemmas: ['present']\n",
      "\n",
      "\n",
      "##### Synset name :  present.n.03 #####\n",
      "POS : noun.communication\n",
      "Definition: a verb tense that expresses actions or states at the time of speaking\n",
      "Lemmas: ['present', 'present_tense']\n",
      "\n",
      "\n",
      "##### Synset name :  show.v.01 #####\n",
      "POS : verb.perception\n",
      "Definition: give an exhibition of to an interested audience\n",
      "Lemmas: ['show', 'demo', 'exhibit', 'present', 'demonstrate']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Synsets 속성: 이름/품사/정의/부명제\n",
    "for i, synset in enumerate(synsets):\n",
    "    print('##### Synset name : ', synset.name(),'#####')\n",
    "    print('POS :', synset.lexname())\n",
    "    print('Definition:', synset.definition())\n",
    "    print('Lemmas:', synset.lemma_names())\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    if i == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Synset 객체의 여러 속성을 통해 보다 자세히 시맨틱 정보를 확인 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree</th>\n",
       "      <th>lion</th>\n",
       "      <th>tiger</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lion</th>\n",
       "      <td>0.07</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiger</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tree  lion  tiger   cat   dog\n",
       "tree   1.00  0.07   0.07  0.08  0.12\n",
       "lion   0.07  1.00   0.33  0.25  0.17\n",
       "tiger  0.07  0.33   1.00  0.25  0.17\n",
       "cat    0.08  0.25   0.25  1.00  0.20\n",
       "dog    0.12  0.17   0.17  0.20  1.00"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# synset 객체를 단어별로 생성\n",
    "tree = wn.synset('tree.n.01')\n",
    "lion = wn.synset('lion.n.01')\n",
    "tiger = wn.synset('tiger.n.02')\n",
    "cat = wn.synset('cat.n.01')\n",
    "dog = wn.synset('dog.n.01')\n",
    "\n",
    "# 여러 객체를 하나의 리스트로 생성\n",
    "entities = [tree , lion , tiger , cat , dog]\n",
    "\n",
    "# 각 객체의 이름 리스트\n",
    "entity_names = [ entity.name().split('.')[0] for entity in entities]\n",
    "\n",
    "# 각 객체별 다른 객체와의 유사도 측정\n",
    "similarities = []\n",
    "\n",
    "for entity in entities:\n",
    "    similarity = [ round(entity.path_similarity(compared_entity), 2) for compared_entity in entities ]\n",
    "    similarities.append(similarity)\n",
    "    \n",
    "similarity_df = pd.DataFrame(similarities , columns=entity_names, index=entity_names)\n",
    "similarity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Synset 객체의 `path_similarity` 속성으로 다른 Synset 객체를 입력하여 단어 유사도를 확인 가능하다.\n",
    "\n",
    "\n",
    "- dog의 경우 cat과 유사도가 가장 높고 tree와의 유사도가 가장 낮다.\n",
    "\n",
    "\n",
    "- 직접 품사, 의미를 지정하여서 `synsets()`가 아닌 `synset()`을 사용하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SentiWordNet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "senti_synsets() 반환 type : <class 'list'>\n",
      "senti_synsets() 반환 값 갯수: 11\n",
      "senti_synsets() 반환 값 : [SentiSynset('decelerate.v.01'), SentiSynset('slow.v.02'), SentiSynset('slow.v.03'), SentiSynset('slow.a.01'), SentiSynset('slow.a.02'), SentiSynset('dense.s.04'), SentiSynset('slow.a.04'), SentiSynset('boring.s.01'), SentiSynset('dull.s.08'), SentiSynset('slowly.r.01'), SentiSynset('behind.r.03')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "\n",
    "senti_synsets = list(swn.senti_synsets('slow'))\n",
    "print('senti_synsets() 반환 type :', type(senti_synsets))\n",
    "print('senti_synsets() 반환 값 갯수:', len(senti_synsets))\n",
    "print('senti_synsets() 반환 값 :', senti_synsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SentiWordNet은 WordNet과 비슷하게 senti_synset 클래스를 가지고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "father 긍정 감성 지수:  0.0\n",
      "father 부정 감성 지수:  0.0\n",
      "father 객관성 지수:  1.0\n",
      "------------------------------\n",
      "fabulous 긍정 감성 지수:  0.875\n",
      "fabulous 부정 감성 지수:  0.125\n",
      "fabulous 객관성 지수:  0.0\n"
     ]
    }
   ],
   "source": [
    "father = swn.senti_synset('father.n.01')\n",
    "\n",
    "print('father 긍정 감성 지수: ', father.pos_score())\n",
    "print('father 부정 감성 지수: ', father.neg_score())\n",
    "print('father 객관성 지수: ', father.obj_score())\n",
    "print(\"-\"*30)\n",
    "\n",
    "fabulous = swn.senti_synset('fabulous.a.01')\n",
    "\n",
    "print('fabulous 긍정 감성 지수: ',fabulous.pos_score())\n",
    "print('fabulous 부정 감성 지수: ',fabulous.neg_score())\n",
    "print('fabulous 객관성 지수: ', fabulous.obj_score())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SentiSynset 객체는 감정 지수(긍정, 부정)와 객관성 지수를 가지고 있다.\n",
    "\n",
    "\n",
    "- 감성 지수와 객관성 지수는 서로 반대 개념으로 감성 지수가 1이면 객관성 지수는 0이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 SentiWordNet 감성 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WordNet 기반의 SentiWordNet의 경우 예측 정확도가 높아 잘 사용하지 않는다고 한다.\n",
    "\n",
    "뒤에 나올 VADER 감성 분석만 참조해도 문제 없다고 하는데 여기선 이해를 위해 실습해보도록 한다.\n",
    "\n",
    "SentiWordNet 감성 분석의 대략적인 순서는 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 문서를 문장 단위로 분해\n",
    "\n",
    "\n",
    "2. 문장을 다시 단어 단위로 토큰화 후 품사 태깅\n",
    "\n",
    "\n",
    "3. 품사 태깅된 단어 기반으로 Synsets, SentiSynset 객체 생성\n",
    "\n",
    "\n",
    "4. SentiSynset에서 긍정/부정 감성 지수를 구하고 합산, 특정 임계치에 따라 긍정/부정 결정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**품사 태깅 함수**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penn_to_wn(tag):\n",
    "    \n",
    "    from nltk.corpus import wordnet as wn\n",
    "    \n",
    "    if tag.startswith('J'):\n",
    "        return wn.ADJ          # 형용사\n",
    "    elif tag.startswith('N'):\n",
    "        return wn.NOUN         # 명사\n",
    "    elif tag.startswith('R'):\n",
    "        return wn.ADV          # 부사\n",
    "    elif tag.startswith('V'):\n",
    "        return wn.VERB         # 동사\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**긍정/부정 예측 함수**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swn_polarity(text):\n",
    "    \n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    from nltk.corpus import sentiwordnet as swn\n",
    "    from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "\n",
    "    # 감성 지수 초기화 \n",
    "    sentiment = 0.0\n",
    "    tokens_count = 0\n",
    "    \n",
    "    # 어근 추출 객체\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    # 문장 토큰화\n",
    "    raw_sentences = sent_tokenize(text) \n",
    "        \n",
    "    # 분해된 문장별로 단어 토큰 -> 품사 태깅 후에 SentiSynset 생성 -> 감성 지수 합산 \n",
    "    for raw_sentence in raw_sentences:\n",
    "        \n",
    "        # 각 문장별 단어 토큰화 후 품사 태깅 문장 추출 (단어와 품사 생성)\n",
    "        tagged_sentence = pos_tag(word_tokenize(raw_sentence))\n",
    "        \n",
    "        for word , tag in tagged_sentence:\n",
    "            \n",
    "            # WordNet 기반 품사 태깅\n",
    "            wn_tag = penn_to_wn(tag)\n",
    "            if wn_tag not in (wn.NOUN , wn.ADJ, wn.ADV):\n",
    "                continue\n",
    "                \n",
    "            # 어근 추출\n",
    "            lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
    "            if not lemma:\n",
    "                continue\n",
    "            \n",
    "            # 어근 추출한 단어, WordNet 기반 품사 태깅을 입력해 Synset 객체 생성 .. (1)\n",
    "            synsets = wn.synsets(lemma , pos=wn_tag)\n",
    "            if not synsets:\n",
    "                continue\n",
    "            \n",
    "            # (1)에서 생성된 synset 객체의 첫 번째 의미 사용 (같은 품사여도 여러 의미 존재) .. (2)\n",
    "            synset = synsets[0]\n",
    "            \n",
    "            # (2)를 이용해서 SentiSynset 객체 생성\n",
    "            swn_synset = swn.senti_synset(synset.name())\n",
    "            \n",
    "            # 긍정 감성 지수 - 부정 감성 지수로 감성 지수 계산\n",
    "            sentiment += (swn_synset.pos_score() - swn_synset.neg_score())           \n",
    "            tokens_count += 1\n",
    "    \n",
    "    if not tokens_count:\n",
    "        return 0\n",
    "    \n",
    "    # 총 score가 0 이상일 경우 긍정(Positive) 1, 그렇지 않을 경우 부정(Negative) 0 반환\n",
    "    if sentiment >= 0 :\n",
    "        return 1\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 앞서 SentiWordNet 감성 분석의 순서에 맞게 예측 하는 함수를 생성하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 문서별로 긍정/부정 예측\n",
    "review_df['preds'] = review_df['review'].apply( lambda x : swn_polarity(x) )\n",
    "\n",
    "y_target = review_df['sentiment'].values\n",
    "preds = review_df['preds'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**평가지표 함수**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "def get_clf_eval(y_test, pred=None, pred_proba_po=None):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    # auc = roc_auc_score(y_test, pred_proba_po)\n",
    "   \n",
    "    print(\"오차 행렬\")\n",
    "    print(confusion)\n",
    "    print(f\"정확도: {accuracy:.4f}, 정밀도: {precision:.4f}, 재현율: {recall:.4f}, F1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [3장 평가](https://romg2.github.io/mlguide/02_%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EC%99%84%EB%B2%BD%EA%B0%80%EC%9D%B4%EB%93%9C-03.-%ED%8F%89%EA%B0%80/)에서 사용한 평가지표 함수를 사용해서 감성 분석 성능을 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[7668 4832]\n",
      " [3636 8864]]\n",
      "정확도: 0.6613, 정밀도: 0.6472, 재현율: 0.7091, F1: 0.6767\n"
     ]
    }
   ],
   "source": [
    "get_clf_eval(y_target, pred=preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 성능 자체는 전체적으로 좋진 않다.\n",
    "\n",
    "\n",
    "- 정확도의 경우 지도학습에 비해 확연히 낮다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 VADER 감성 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VADER는 소셜 미디어 감성 분석 용도로 만들어진 Lexicon이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.119, 'neu': 0.755, 'pos': 0.126, 'compound': -0.0678}\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "senti_analyzer = SentimentIntensityAnalyzer()\n",
    "senti_scores = senti_analyzer.polarity_scores(review_df['review'][0])\n",
    "\n",
    "# dictionary로 반환\n",
    "print(senti_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `SentimentIntensityAnalyzer()`로 생성된 객체의 `polarity_scores()`를 이용하여 감성 분석 수행이 가능하다.\n",
    "\n",
    "\n",
    "- neg는 부정, neu는 중립, pos는 긍정, compound는 neg, neu, pos를 조합해 만든 감성 지수이다.\n",
    "\n",
    "\n",
    "- compound는 -1 ~ 1 사이의 값을 가지며 보통 0.1 이상이면 긍정으로 판단한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**임계치별 긍정/부정 예측 함수**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_polarity(review, threshold = 0.1):\n",
    "    from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "    \n",
    "    # VADER 객체로 감성 지수 산출\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(review)\n",
    "    \n",
    "    # 감성 지수가 threshold 보다 크거나 같으면 1, 그렇지 않으면 0\n",
    "    agg_score = scores['compound']\n",
    "    final_sentiment = 1 if agg_score >= threshold else 0\n",
    "        \n",
    "    return final_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 문서별로 긍정/부정 예측\n",
    "review_df['vader_preds'] = review_df['review'].apply( lambda x : vader_polarity(x, 0.1) )\n",
    "\n",
    "y_target = review_df['sentiment'].values\n",
    "vader_preds = review_df['vader_preds'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[ 6729  5771]\n",
      " [ 1858 10642]]\n",
      "정확도: 0.6948, 정밀도: 0.6484, 재현율: 0.8514, F1: 0.7361\n"
     ]
    }
   ],
   "source": [
    "get_clf_eval(y_target, pred=vader_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SentiWordNet에 비해 전반적으로 성능이 향상 되었고 재현율은 크게 증가하였다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "310.417px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
