{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**기본 세팅**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "mpl.rc('font', family='NanumGothic') # 폰트 설정\n",
    "mpl.rc('axes', unicode_minus=False) # 유니코드에서 음수 부호 설정\n",
    "\n",
    "# 차트 스타일 설정\n",
    "sns.set(font=\"NanumGothic\", rc={\"axes.unicode_minus\":False}, style='darkgrid')\n",
    "plt.rc(\"figure\", figsize=(10,8))\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 스태킹 앙상블"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스태킹은 개별적인 여러 알고리즘을 서로 결합해 예측 결과를 도출한다는 점에서 배깅 및 부스팅과 공통점이 있다.\n",
    "\n",
    "하지만 가장 큰 차이점은 개별 알고리즘으로 예측한 데이터를 기반으로 다시 예측을 수행한다는 점이다.\n",
    "\n",
    "즉, 개별 알고리즘의 예측 결과 데이터 셋을 최종적인 메타 데이터 셋으로 만든 후 별도의 ML 알고리즘으로 최종 학습 및 예측을 진행하는 방식이다.\n",
    "\n",
    "이런식으로 개별 모델의 예측 데이터를 기반으로 학습하고 예측하는 방식을 메타 모델이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 기본 스태킹 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 개별 모델 학습/예측/평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 위스콘신 유방암 데이터\n",
    "cancer_data = load_breast_cancer()\n",
    "\n",
    "X_data = cancer_data.data\n",
    "y_label = cancer_data.target\n",
    "\n",
    "X_train , X_test , y_train , y_test = train_test_split(X_data , y_label , test_size=0.2 , random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=100)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 개별 ML 모델\n",
    "knn_clf  = KNeighborsClassifier(n_neighbors=4)\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "dt_clf = DecisionTreeClassifier(random_state=0)\n",
    "ada_clf = AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "# 최종 모델\n",
    "lr_final = LogisticRegression(C=10)\n",
    "\n",
    "# 개별 모델 학습\n",
    "knn_clf.fit(X_train, y_train)\n",
    "rf_clf.fit(X_train , y_train)\n",
    "dt_clf.fit(X_train , y_train)\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- KNN, 랜덤 포레스트, 결정 트리, 에이다부스트를 개별 모델로 설정하고 최종 모델은 로지스틱으로 설정하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 정확도: 0.9211\n",
      "랜덤 포레스트 정확도: 0.9649\n",
      "결정 트리 정확도: 0.9123\n",
      "에이다부스트 정확도: 0.9561\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 개별 모델 예측 데이터 셋 및 정확도\n",
    "knn_pred = knn_clf.predict(X_test)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "dt_pred = dt_clf.predict(X_test)\n",
    "ada_pred = ada_clf.predict(X_test)\n",
    "\n",
    "knn_acc = accuracy_score(y_test, knn_pred)\n",
    "rf_acc = accuracy_score(y_test, rf_pred)\n",
    "dt_acc = accuracy_score(y_test, dt_pred)\n",
    "ada_acc = accuracy_score(y_test, ada_pred)\n",
    "\n",
    "print(f'KNN 정확도: {knn_acc:.4f}')\n",
    "print(f'랜덤 포레스트 정확도: {rf_acc:.4f}')\n",
    "print(f'결정 트리 정확도: {dt_acc:.4f}')\n",
    "print(f'에이다부스트 정확도: {ada_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 개별 모델로 test set 예측 결과를 저장하고 성능 평가를 진행하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 메타 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 114)\n",
      "(114, 4)\n"
     ]
    }
   ],
   "source": [
    "# 개별 예측 결과를 stacking\n",
    "pred = np.array([knn_pred, rf_pred, dt_pred, ada_pred])\n",
    "print(pred.shape)\n",
    "\n",
    "# 개별 모델의 예측 결과를 피처로 생성\n",
    "pred = pred.T\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 개별 모델의 예측 결과를 결합하고 전치하여 메타 데이터를 생성한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 최종 학습/예측/평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 메타 모델의 예측 정확도: 0.9737\n"
     ]
    }
   ],
   "source": [
    "lr_final.fit(pred, y_test)\n",
    "final = lr_final.predict(pred)\n",
    "lr_final_acc = accuracy_score(y_test , final)\n",
    "\n",
    "print(f'최종 메타 모델의 예측 정확도: {lr_final_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 개별 모델의 정확도에 비해 성능이 향상된 것이 확인 된다(무조건 향상되는 것은 아니다)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 CV 스태킹 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 작업은 개별 모델로 test set의 예측 결과를 결합해 메타 데이터를 생성\n",
    "\n",
    "메타 데이터와 test set으로 최종 모델 학습, 최종 모델을 이용해 메타 데이터의 예측/평가를 진행하였다.\n",
    "\n",
    "이러한 방법은 다음과 같은 문제가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 최종 학습에 test set을 사용했기에 과적합 문제가 발생할 수 있다.\n",
    "\n",
    "\n",
    "- 또한 최종 학습에 메타 데이터를 사용하고 메타 데이터에 대한 예측을 진행하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV 스태킹은 이를 개선한 방법으로 다음 예시로 이해해보자.\n",
    "\n",
    "- 개별 모델이 4개이고, 데이터는 100개로 train 60개, test 40개, fold는 3이라 가정\n",
    "\n",
    "\n",
    "- 첫 번째 모델에서 train 60개에 대해 학습시 train_fold 40개, test_fold 20개로 예측을 진행할 것이다.\n",
    "\n",
    "\n",
    "- 각 fold별로 예측값은 20개씩 3번 구해지고 train 갯수와 같은 총 60개의 예측값을 얻을 수 있을 것이다. 이를 train 메타 데이터로 사용한다.\n",
    "\n",
    "\n",
    "- 각 fold별로 test_fold가 아닌 test에 대해 예측을 진행한다. 즉, train_fold 40개로 test 40개를 예측한다. \n",
    "\n",
    "\n",
    "- 3번 반복하면 40개씩 3묶음의 예측 데이터가 생성될 것이다. 이를 평균내어 40개의 test 메타 데이터로 사용한다.\n",
    "\n",
    "\n",
    "- 개별 모델이 4개이므로 train 메타 데이터는 60 x 4, test 메타 데이터는 40 x 4로 생성 된다.\n",
    "\n",
    "\n",
    "- train 메타 데이터를 피처로, y_train을 레이블로 학습 후, test 메타 데이터에 대해 예측하고 y_test와 비교로 평가한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 CV 스태킹 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# 개별 모델별 메타 데이터\n",
    "def get_stacking_base_datasets(model, X_train, y_train, X_test, n_folds ):\n",
    "    # KFold 생성\n",
    "    kf = KFold(n_splits=n_folds, shuffle=False, random_state=0)\n",
    "    \n",
    "    # 메타 데이터 반환을 위한 기본 배열\n",
    "    train_cnt = X_train.shape[0]\n",
    "    test_cnt = X_test.shape[0]\n",
    "    train_meta = np.zeros((train_cnt, 1))\n",
    "    test_meta = np.zeros((test_cnt, n_folds))\n",
    "    \n",
    "    print(model.__class__.__name__ , ' model 시작 ')\n",
    "    \n",
    "    # train 데이터를 기반으로 fold를 나눠 학습/예측\n",
    "    for i , (train_fold_idx, test_fold_index) in enumerate(kf.split(X_train)):\n",
    "        # train, test fold 생성\n",
    "        print(f'\\t 폴드 세트: {i+1} 시작 ')\n",
    "        x_train_fold = X_train[train_fold_idx] \n",
    "        y_train_fold = y_train[train_fold_idx] \n",
    "        x_test_fold = X_train[test_fold_index]  \n",
    "        \n",
    "        # train_fold로 학습\n",
    "        model.fit(x_train_fold , y_train_fold)       \n",
    "        \n",
    "        # train 메타 데이터 생성 (x_test_fold 예측)\n",
    "        train_meta[test_fold_index, :] = model.predict(x_test_fold).reshape(-1,1)\n",
    "        \n",
    "        # test 메타 데이터 생성 (x_test 예측) - 평균 전\n",
    "        test_meta[:, i] = model.predict(X_test)\n",
    "            \n",
    "    # test 메타 데이터 생성 - 평균 진행\n",
    "    test_meta_mean = np.mean(test_meta, axis=1).reshape(-1,1)    \n",
    "    \n",
    "    # train test 메타 데이터 반환\n",
    "    return train_meta , test_meta_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier  model 시작 \n",
      "\t 폴드 세트: 1 시작 \n",
      "\t 폴드 세트: 2 시작 \n",
      "\t 폴드 세트: 3 시작 \n",
      "\t 폴드 세트: 4 시작 \n",
      "\t 폴드 세트: 5 시작 \n",
      "\t 폴드 세트: 6 시작 \n",
      "\t 폴드 세트: 7 시작 \n",
      "RandomForestClassifier  model 시작 \n",
      "\t 폴드 세트: 1 시작 \n",
      "\t 폴드 세트: 2 시작 \n",
      "\t 폴드 세트: 3 시작 \n",
      "\t 폴드 세트: 4 시작 \n",
      "\t 폴드 세트: 5 시작 \n",
      "\t 폴드 세트: 6 시작 \n",
      "\t 폴드 세트: 7 시작 \n",
      "DecisionTreeClassifier  model 시작 \n",
      "\t 폴드 세트: 1 시작 \n",
      "\t 폴드 세트: 2 시작 \n",
      "\t 폴드 세트: 3 시작 \n",
      "\t 폴드 세트: 4 시작 \n",
      "\t 폴드 세트: 5 시작 \n",
      "\t 폴드 세트: 6 시작 \n",
      "\t 폴드 세트: 7 시작 \n",
      "AdaBoostClassifier  model 시작 \n",
      "\t 폴드 세트: 1 시작 \n",
      "\t 폴드 세트: 2 시작 \n",
      "\t 폴드 세트: 3 시작 \n",
      "\t 폴드 세트: 4 시작 \n",
      "\t 폴드 세트: 5 시작 \n",
      "\t 폴드 세트: 6 시작 \n",
      "\t 폴드 세트: 7 시작 \n"
     ]
    }
   ],
   "source": [
    "knn_train, knn_test = get_stacking_base_datasets(knn_clf, X_train, y_train, X_test, 7)\n",
    "rf_train, rf_test = get_stacking_base_datasets(rf_clf, X_train, y_train, X_test, 7)\n",
    "dt_train, dt_test = get_stacking_base_datasets(dt_clf, X_train, y_train, X_test,  7)    \n",
    "ada_train, ada_test = get_stacking_base_datasets(ada_clf, X_train, y_train, X_test, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각 모델별로 train, test 메타 데이터를 생성하였고 이를 합치기만 하면 최종 메타 데이터가 완성된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 메타 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 train 피처 데이터 Shape: (455, 30)\n",
      "원본 test 피처 데이터 Shape: (114, 30)\n",
      "최종 train 피처 메타 데이터 Shape: (455, 4)\n",
      "최종 test 피처 메타 데이터 Shape: (114, 4)\n"
     ]
    }
   ],
   "source": [
    "final_X_train_meta = np.concatenate((knn_train, rf_train, dt_train, ada_train), axis=1)\n",
    "final_X_test_meta = np.concatenate((knn_test, rf_test, dt_test, ada_test), axis=1)\n",
    "\n",
    "print('원본 train 피처 데이터 Shape:',X_train.shape)\n",
    "print('원본 test 피처 데이터 Shape:',X_test.shape)\n",
    "print('최종 train 피처 메타 데이터 Shape:', final_X_train_meta.shape)\n",
    "print('최종 test 피처 메타 데이터 Shape:',final_X_test_meta.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 최종 메타 데이터가 잘 생성되었고 한 가지, 메타 데이터의 열 갯수는 개별 모델 갯수임을 기억하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 최종 학습/예측/평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 메타 모델의 예측 정확도: 0.9737\n"
     ]
    }
   ],
   "source": [
    "lr_final.fit(final_X_train_meta, y_train)\n",
    "final_pred = lr_final.predict(final_X_test_meta)\n",
    "final_acc = accuracy_score(y_test, final_pred)\n",
    "print(f'최종 메타 모델의 예측 정확도: {final_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 정확도 수치 자체는 기본 스태킹 모델과 동일하게 나타났다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 참고사항"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지 예제에서 개별 모델의 파라미터를 튜닝하지 않았다.\n",
    "\n",
    "실제로 스태킹을 진행할 때는 각 개별 모델에서 최적 파라미터로 튜닝 후 스태킹 모델을 만들어야한다.\n",
    "\n",
    "스태킹 모델을 현실에서 적용하는 경우는 드물지만 캐글 대회 등에서 성능을 조금이라도 올리고 싶을때 사용된다.\n",
    "\n",
    "스태킹 모델을 사용할 땐 많은 개별 모델이 있어야 예측 성능이 향상된다(물론 반드시 성능 향상이 되는 것은 아니다)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "310.417px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
